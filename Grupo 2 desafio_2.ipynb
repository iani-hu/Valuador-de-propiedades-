{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desaf√≠o 2. Prediciendo precios de propiedades\n",
    "\n",
    "**Grupo 2:**\n",
    "\n",
    "Faro, Gonzalo\n",
    "\n",
    "Cabrol, Angelica\n",
    "\n",
    "Vinyolas, Mariana\n",
    "\n",
    "Hutler, Ianina\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [√çndice](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Objetivos](#Objetivos)\n",
    "- [Indicaciones](#Indicaciones)\n",
    "- [Importaci√≥n de librer√≠as](#Importaci√≥n-de-librer√≠as)\n",
    "- [Seteos Generales](#Seteos-Generales)\n",
    "- [Feature Selection](#Feature-Selection)\n",
    "- [An√°lisis de propiedades en Argentina](#An√°lisis-de-Propiedades-en-Argentina)\n",
    "- [An√°lisis de propiedades en CABA](#An√°lisis-de-Propiedades-en-CABA)\n",
    "- [An√°lisis de propiedades en GBA](#An√°lisis-de-Propiedades-en-GBA)\n",
    "- [An√°lisis de propiedades en Provincia De Buenos Aires](#An√°lisis-de-Propiedades-en-Provincia-de-Buenos-Aires)\n",
    "- [An√°lisis de propiedades en Patagonia](#An√°lisis-de-Propiedades-en-Patagonia)\n",
    "- [An√°lisis de propiedades en Regi√≥n Pampeana](#An√°lisis-de-Propiedades-en-Regi√≥n-Pampeana)\n",
    "- [An√°lisis de propiedades en Noroeste](#An√°lisis-de-Propiedades-en-Noroeste)\n",
    "- [An√°lisis de propiedades en Nordeste](#An√°lisis-de-Propiedades-en-Nordeste)\n",
    "- [An√°lisis de propiedades en Cuyo](#An√°lisis-de-Propiedades-en-Cuyo)\n",
    "- [An√°lisis de Sample en CABA](#An√°lisis-de-Sample-en-CABA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Objetivos](#Objetivos)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivos:\n",
    "\n",
    "‚óè Estimar un modelo de regresi√≥n lineal que realice predicciones para el precio por metro cuadrado. Deber√° prestar cierta atenci√≥n a la estructura espacial de los precios.\n",
    "\n",
    "‚óè Aplicar regularizaci√≥n a modelos lineales (pueden hacerlo para obtener un puntaje adicional). La idea es la siguiente: estimar una regresi√≥n Ridge y una LASSO sobre el dataset. Para ello, deber√°n usar cross-validation para tunear el par√°metro de regularizaci√≥n que maximiza R2 en tu test set. ¬øC√≥mo son las performances entre los modelos regularizados y no regularizado? ¬øCu√°l funciona mejor? ¬øQu√© hace una regresi√≥n Ridge? ¬øY una LASSO?¬øQu√© diferencias hay con la regresi√≥n lineal sin regularizar?\n",
    "\n",
    "‚óè Seleccionar mediante muestreo aleatorio simple una submuestra de 100 propiedades. Este ser√° su portafolio de departamentos. En base al mejor modelo que haya encontrado determine cu√°les de los departamentos, tanto en su portafolio como fuera de √©l, se encuentran sobrevaluados o subvaluados y en qu√© magnitud.\n",
    "\n",
    "‚óè Teniendo en cuenta que podr√≠a comprar y vender propiedades al precio de mercado, omitamos costos de transacci√≥n, con un capital inicial igual al valor de mercado de las propiedades en su portafolio. ¬øCu√°l es el mejor portafolio de propiedades que podr√≠a comprar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Indicaciones](#Indicaciones)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trabajo se organizar√° de la siguiente manera:\n",
    "\n",
    "1- An√°lisis de propiedades en Argentina.\n",
    "\n",
    "2- An√°lisis de propiedades en CABA.\n",
    "\n",
    "2.1 An√°lisis de propiedades en CABA por tipo de propiedad.\n",
    "\n",
    "3- An√°lisis de propiedades en el Gran Buenos Aires (gba).\n",
    "\n",
    "4- An√°lisis de propiedades en Bs As provincia.\n",
    "\n",
    "5- An√°lisis de propiedades en Patagonia.\n",
    "\n",
    "6- An√°lisis de propiedades en la regi√≥n pampeana.\n",
    "\n",
    "7- An√°lisis de propiedades en la regi√≥n noroeste.\n",
    "\n",
    "8- An√°lisis de propiedades en la regi√≥n nordeste. \n",
    "\n",
    "9- An√°lisis de propiedades en la regi√≥n de Cuyo.\n",
    "\n",
    "10- Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Importaci√≥n de librer√≠as](#Importaci√≥n-de-librer√≠as)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos los diferentes paquetes a utilizar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Seteos Generales](#Seteos-Generales)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteos generales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Feature Selection](#Feature-Selection)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection:**\n",
    "\n",
    "Para predecir el precio por metro cuadrado de las propiedades de Argentina seleccionamos como relevantes las siguientes features: tama√±o de la propiedad (superficie total en m2), el tipo de propiedad (PH, departamento, negocio o casa), cantidad de ambientes (rooms), ubicaci√≥n (barrio, provincia o localidad), amenities (pileta, parrila, gimnasio, sauna, laundry, playroom, sum, sala de reuniones, restaurant y quincho), si tiene o no superficie descubierta (terraza, balc√≥n o patio), si tiene o no expensas, si tiene garage o cochera, si tiene o no vigilancia, si tiene o no dependencia, si es a estrenar, en refacci√≥n o normal (ninguna de las dos anteriores) y si se encuentra en un barrio cerrado o country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Argentina](#An√°lisis-de-Propiedades-en-Argentina)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis de propiedades en Argentina. ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargamos el DataFrame de Argentina**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arg = pd.read_csv('df_total.csv', index_col=0)\n",
    "display(df_arg.shape) # Nos fijamos cuantas filas y columnas tiene\n",
    "display(df_arg.sample(10)) # Selecci√≥n de 10 ejemplares al azar para su observaci√≥n\n",
    "display(df_arg.isnull().sum()) # Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es = df_arg[df_arg['surface_total_in_m2']<=15]\n",
    "quien_es['surface_total_in_m2'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas geonames_id, lat-lon, lat, lon, price_aprox_usd, localidad y barrio no van a ser utilizadas. \n",
    "La columna de provincia es la que vamos a utilizar para crear dummies y no tiene ningun valor null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos Variables Dummies para las provincias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prov_dummies = pd.get_dummies(df_arg.provincia, prefix='Provincia')\n",
    "df_arg = pd.concat([df_arg, prov_dummies], axis=1) \n",
    "display(df_arg.shape)\n",
    "display(df_arg.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las filas con valores nan para surface_total_in_m2, price_usd_per_m y rooms que son las que voy a conservar para el an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg = df_arg[(df_arg.surface_total_in_m2.notnull())\\\n",
    "                  & (df_arg.price_usd_per_m2.notnull())\\\n",
    "                  & (df_arg.rooms.notnull())]\n",
    "display(df_arg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de la columna amenities**\n",
    "\n",
    "Recuperamos por regex las siguientes amenities: pileta, parrilla, gimnasio, sauna, laundry, playroom, sum, sala de reuniones, restaurant y quincho. Creamos un contador y vemos con cuantos amenities cuenta la propiedad. Decidimos entonces eliminar las amenities por separado y quedarnos con el contador. A continuaci√≥n tambi√©n eliminamos el resto de las columnas que no va a participar en el an√°lisis. Esto se repetir√° en todas las regiones de Argentina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', 'price_aprox_usd', 'pileta', \n",
    "         'parrilla', 'gimnasio', 'sauna', 'expenses', 'laundry', 'playroom', 'sum', 'sala_reuniones', 'restaurant',\n",
    "         'quincho'], inplace=True, axis=1)\n",
    "display(df_arg.shape)\n",
    "display(df_arg.sample(5))\n",
    "display(df_arg.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 41217 filas y 47 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresi√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_arg.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_arg.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos para train y test utilizando la funci√≥n de Scikit-learn que se encarga de la separaci√≥n entre test y entrenamiento. Seteamos el par√°metro test_size en 0.3 que ser√° la propoci√≥n de los datos que vamos a separar para hacer la evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante estandarizar todos los regresores antes de ejecutar una regresi√≥n Ridge y Lasso. As√≠ ya no est√°n en unidades f√≠sicas sino en unidades de su propio desv√≠o est√°ndar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sobre el set de entrenamiento (Train Set)***\n",
    "\n",
    "Proceso de Tunning de los Hiperpar√°metros: Asignamos los alphas y definimos kfold como estrategia de cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.1, 10000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el Score de entrenamiento de cada modelo.\n",
    "El coeficiente de determinaci√≥n, denominado R¬≤ representa cu√°nta varianza explica el modelo del total de varianza existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que apesar de que el R2 es muy bajo, mejora levemente con el test y el RMSE baja. Vamos a probar el mismo procedimiento eliminando outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaci√≥n de outliers en Argentina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "import seaborn as sns\n",
    "sns.boxplot(x=df_arg['price_usd_per_m2']) #observaci√≥n de los outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arg['price_usd_per_m2'].describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el cuantil 75 es razonable pero hay un maximo de $ 540.000 que podriamos filtrar para ver si el modelo mejora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg_out = pd.read_csv('df_total.csv', index_col=0) #importo nuevamente el archivo de argentina bajo otro nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_arg_out \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 2: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 2:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos el procedimiento: Generamos Variables Dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prov_dummies = pd.get_dummies(df.provincia, prefix='Provincia')\n",
    "df = pd.concat([df, prov_dummies], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.surface_total_in_m2.notnull())\\\n",
    "        & (df.price_usd_per_m2.notnull())\\\n",
    "        & (df.rooms.notnull())]\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['price_usd_per_m2'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es = df[df['price_usd_per_m2']>=20000] \n",
    "quien_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', 'price_aprox_usd', 'pileta', \n",
    "         'parrilla', 'gimnasio', 'sauna', 'expenses', 'laundry', 'playroom', 'sum', 'sala_reuniones', 'restaurant',\n",
    "         'quincho'],inplace=True, axis=1)\n",
    "display(df.shape)\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresi√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42) # Separamos los datos para train y test\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.01, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el Score de entrenamiento de cada modelo y observamos nuevamente el R¬≤ y RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusi√≥n:**\n",
    "Luego de aplicar el filtro de los outliers tanto R2 como  RMSE se mantuvieron con el mismo valor aproximadamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [An√°lisis de Propiedades en CABA](#An√°lisis-de-propiedades-en-CABA)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. An√°lisis de propiedades en CABA. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargamos el DataFrame de CABA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_caba = pd.read_csv('df_caba.csv', index_col=0)\n",
    "display(df_caba.shape) #Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_caba.sample(10)) #Seleccionamos un sample de 10 para que el muestreo sea aleatorio\n",
    "display(df_caba.isnull().sum())#Verificamos si hay valores faltantes\n",
    "display(df_caba['price_usd_per_m2'].describe()) #Observamos los estadisticos para la columna price_usd_per_m2 para ver posibles outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que en el DataFrame de Argentina el modelo de regresi√≥n mejor√≥ gracias a eliminar algunos outliers decidimos implementar lo mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_caba\n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['outlier'], inplace=True, axis=1)\n",
    "df_caba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas geonames_id, lat-lon, lat, lon, price_aprox_usd, provincia y barrio no van a ser utilizadas. \n",
    "La columna de localidad es la que vamos a utilizar para crear dummies y no tiene ningun valor null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las filas con valores nan para surface_total_in_m2, price_usd_per_m2,rooms y localidad que son las que voy a conservar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_caba = df_caba[(df_caba.surface_total_in_m2.notnull())\\\n",
    "                  & (df_caba.price_usd_per_m2.notnull())\\\n",
    "                  & (df_caba.rooms.notnull())\\\n",
    "                  & (df_caba.localidad.notnull())]\n",
    "display(df_caba.shape)\n",
    "display(df_caba.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Como son muchas las dummies de amenities las eliminamos solo para ver el heatmap, dejando el contador amenities ####\n",
    "\n",
    "df_heatmap = df_caba.drop(['amenities', 'geonames_id', 'lat-lon', 'lat','lon', 'provincia', 'barrio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (40, 25)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_heatmap.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos variables dummies para los barrios de CABA. (dicha informaci√≥n viene contenida en la columna localidad).\n",
    "Luego unimos estas dummies con el DataFrame de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrios_dummies = pd.get_dummies(df_caba.localidad, prefix='barrio')\n",
    "df_caba = pd.concat([df_caba, barrios_dummies], axis=1) \n",
    "df_caba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_caba.head())\n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, las columnas que vamos a utilizar son: surface_total_in_m2, price_usd_per_m2, rooms, terraza, balc√≥n, patio, expensas, barrio_cerrado (que tambi√©n incluye country),vigilancia, si tiene dependencia (habitaci√≥n de servicio), estrenar, normal, refacci√≥n y cochera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos un dataframe, en lugar de obtener el sample, para asegurarnos que haya al menos un registro\n",
    "# por cada tipo de propiedad. Para generar una muestra en el momento, descomentar las siguientes 3 lineas\n",
    "# y comentar las ultimas 2\n",
    "# df_sample = df_caba.sample(100)\n",
    "# df_caba = df_caba.drop( df_sample.index)\n",
    "# df_sample.to_csv('caba_sample.csv')\n",
    "\n",
    "df_sample = pd.read_csv('caba_sample.csv', index_col=0)\n",
    "df_caba = df_caba.drop( df_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_caba.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_caba.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probamos los resultados sacando outliers y dividiendo por tipo de propiedad en CABA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba = pd.read_csv('df_caba.csv', index_col=0) #Cargamos el df de CABA nuevamente \n",
    "df_caba = df_caba[(df_caba.surface_total_in_m2.notnull())\\\n",
    "                  & (df_caba.price_usd_per_m2.notnull())\\\n",
    "                  & (df_caba.rooms.notnull())\\\n",
    "                  & (df_caba.localidad.notnull())]\n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analizamos las propiedades de Boedo\n",
    "df_boedo = df_caba[(df_caba.localidad == 'Boedo')]\n",
    "df_boedo.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se verifica que muchas de las propiedades tienen en precio en ARS, las pasamos a USD\n",
    "df_boedo.price_usd_per_m2 = df_boedo.price_usd_per_m2.apply( lambda x: x / 17.6445 if x > 7000 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boedo.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba = df_caba[(df_caba.localidad != 'Boedo')]\n",
    "df_caba = pd.concat([df_caba, df_boedo], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos las propiedades de San Cristobal\n",
    "df_sancri = df_caba[(df_caba.localidad == 'San Cristobal')]\n",
    "df_sancri.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_sancri.price_usd_per_m2 > 7000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se verifica que muchas de las propiedades tienen en precio en ARS, las pasamos a USD\n",
    "df_sancri.price_usd_per_m2 = df_sancri.price_usd_per_m2.apply( lambda x: x / 17.6445 if x > 7000 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sancri.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba = df_caba[(df_caba.localidad != 'San Cristobal')]\n",
    "df_caba = pd.concat([df_caba, df_sancri], ignore_index=True)\n",
    "df_caba.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos una funcion para eliminar Outliers\n",
    "df=df_caba\n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generamos variables dummies para los barrios de CABA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrios_dummies = pd.get_dummies(df_caba.localidad, prefix='barrio')\n",
    "df_caba = pd.concat([df_caba, barrios_dummies], axis=1) \n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no vamos a utilzar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_caba.head())\n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separamos el df seg√∫n el tipo de propiedad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph = df_caba[(df_caba.PH== 1)]\n",
    "df_ph.drop(['apartment', 'store', 'house', 'PH'], inplace=True, axis=1)\n",
    "df_apartment = df_caba[(df_caba.apartment== 1)]\n",
    "df_apartment.drop(['PH', 'store', 'house', 'apartment'], inplace=True, axis=1)\n",
    "df_store = df_caba[(df_caba.store== 1)]\n",
    "df_store.drop(['PH', 'apartment', 'house','store'], inplace=True, axis=1)\n",
    "df_house = df_caba[(df_caba.house== 1)]\n",
    "df_house.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "\n",
    "display(df_ph.head())\n",
    "display(df_ph.shape)\n",
    "display(df_apartment.head())\n",
    "display(df_apartment.shape)\n",
    "display(df_store.head())\n",
    "display(df_store.shape)\n",
    "display(df_house.head())\n",
    "display(df_house.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelos de Regresi√≥n**\n",
    "\n",
    "\n",
    "Tipo de Propiedad: 'PH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_ph.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_ph.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ph = StandardScaler() #estandarizamos los datos\n",
    "X_train = scaler_ph.fit_transform(X_train)\n",
    "X_test = scaler_ph.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.1, 100, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_ph = lm.fit(X_train, y_train)\n",
    "modelo_ridge_ph = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_ph = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", fontsize='small')\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", fontsize='small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribuci√≥n de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes para cada modelo: 'PH' Intercept y coef de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de LM para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada feature y los coef calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tipo de Propiedad: 'APARTMENT'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_apartment.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_apartment.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ap = StandardScaler() #estandarizamos\n",
    "X_train = scaler_ap.fit_transform(X_train)\n",
    "X_test = scaler_ap.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.01, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_ap = lm.fit(X_train, y_train)\n",
    "modelo_ridge_ap = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_ap = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribuci√≥n de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes para cada modelo: 'APARTMENT' Intercept y coef de cada feature (fichur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos los coeficientes de LM para cada feature en PH\n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada fichur y los coef calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True, cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de Propiedad: 'HOUSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos X e y\n",
    "X_df = df_house.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_house.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ho = StandardScaler()\n",
    "X_train = scaler_ho.fit_transform(X_train)\n",
    "X_test = scaler_ho.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_ho = lm.fit(X_train, y_train)\n",
    "modelo_ridge_ho = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_ho = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribuci√≥n de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de LM para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada feature y los coeficientes calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True, cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de Propiedad: 'STORE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos X e y\n",
    "X_df = df_store.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_store.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_st = StandardScaler()\n",
    "X_train = scaler_st.fit_transform(X_train)\n",
    "X_test = scaler_st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_st = lm.fit(X_train, y_train)\n",
    "modelo_ridge_st = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_st = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribuci√≥n de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes para cada modelo: 'STORE' Intercept y coef de cada feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de LM para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada fichur y los coef calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True, cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en GBA](#An√°lisis-de-propiedades-en-GBA)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de propiedades en el Gran Buenos Aires (gba) ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gba = pd.read_csv('df_gba.csv', index_col=0)\n",
    "display(df_gba.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_gba.sample(5))#elegimos un sample de 10 para que el muestreo sea aleatorio\n",
    "df_gba.isnull().sum()# Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2 y rooms.\n",
    "df_gba = df_gba[(df_gba.surface_total_in_m2.notnull())\n",
    "                  & (df_gba.price_usd_per_m2.notnull())\n",
    "                  & (df_gba.rooms.notnull())\n",
    "                  & (df_gba.localidad.notnull())]\n",
    "df_gba.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generamos las dummies para barrios (usando la columna de localidad que es la que contiene dicha informaci√≥n)\n",
    "gba_dummies = pd.get_dummies(df_gba.localidad, prefix='barrio')\n",
    "gba_dummies.columns\n",
    "df_gba = pd.concat([df_gba, gba_dummies], axis=1) #concatenamos las dummies generadas con el df de gba\n",
    "df_gba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n. \n",
    "df_gba.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_gba.sample(5))\n",
    "display(df_gba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 15212 filas y  51 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# definimos X e y\n",
    "X_gba = df_gba.drop('price_usd_per_m2', axis=1)\n",
    "y_gba = df_gba.price_usd_per_m2\n",
    "display(X_gba.shape)\n",
    "display(y_gba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gba, y_gba, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asignamos los alphas\n",
    "alphas = np.linspace(0.1, 10000, 300)\n",
    "\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir por regi√≥n del GBA para ver si estos resultados mejoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_df_gba( df_param ):\n",
    "    #generamos las dummies para barrios (usando la columna de localidad que es la que contiene dicha informaci√≥n)\n",
    "    gba_dummies = pd.get_dummies(df_param.localidad, prefix='barrio')\n",
    "    gba_dummies.columns\n",
    "    df_retorno = pd.concat([df_param, gba_dummies], axis=1) #concatenamos las dummies generadas con el df de gba\n",
    "\n",
    "    # #Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n. Saco del df el contador de amenities\n",
    "    df_retorno.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "                 'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "                 'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "                  inplace=True, axis=1)\n",
    "    display(df_retorno.sample(5))\n",
    "    display(df_retorno.shape)\n",
    "    return df_retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers( df, criterio, p_z_score ):\n",
    "    criterios = df[ criterio ].unique()\n",
    "    for x in criterios:\n",
    "           mean_1 = np.mean( df.price_usd_per_m2[ ( df[ criterio ] ==x ) ] )\n",
    "           std_1 = np.std( df.price_usd_per_m2[ ( df[ criterio ] ==x ) ] )\n",
    "           mean_2 = np.mean( df.surface_total_in_m2[ ( df[ criterio ] == x ) ] )\n",
    "           std_2 = np.std( df.surface_total_in_m2[ ( df[ criterio ] == x ) ] )\n",
    "\n",
    "           for index2, y in df[ ( df[ criterio ] == x ) ].iterrows():\n",
    "                   if( std_1 != 0 ):\n",
    "                       z_score = ( y.price_usd_per_m2 - mean_1 )/std_1\n",
    "                       if np.abs( z_score ) > p_z_score:\n",
    "                           df.loc[ index2, 'outlier' ] = \"YES\"\n",
    "                   if( std_2 != 0 ):\n",
    "                       z_score2= ( y.surface_total_in_m2 - mean_2 )/std_2\n",
    "                       if np.abs( z_score2 ) > p_z_score:\n",
    "                           df.loc[ index2, 'outlier' ]=\"YES\"\n",
    "\n",
    "    df = df[(df.outlier!='YES')]\n",
    "    df.drop(['outlier'],inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fit_transform( df, y_val ):\n",
    "    # Zona Norte\n",
    "    # definimos X e y\n",
    "    X_df = df.drop(y_val, axis=1)\n",
    "    y_df = df[ y_val ]\n",
    "    display(X_df.shape)\n",
    "    display(y_df.shape)\n",
    "\n",
    "    # separamos los datos para train y test\n",
    "    X_train_no_norm, X_test_no_norm, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "    print(X_train_no_norm.shape, y_train.shape)\n",
    "    print(X_test_no_norm.shape, y_test.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_no_norm) \n",
    "    X_test = scaler.transform(X_test_no_norm)\n",
    "\n",
    "    #asignamos los alphas\n",
    "    alphas = np.linspace(0.1, 1000, 300)\n",
    "\n",
    "    # Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=68)\n",
    "\n",
    "    #Instanciamos los modelos \n",
    "    lm = LinearRegression()\n",
    "    lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "    lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)\n",
    "\n",
    "    # Entrenamos los modelos\n",
    "    modelo_lr = lm.fit(X_train, y_train)\n",
    "    modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "    modelo_lasso = lm_lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "    #Imprimimos el alpha que eligio para cada modelo\n",
    "    print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "          'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')\n",
    "\n",
    "    # Calculamos el RMSE\n",
    "\n",
    "    y_pred_tr_lm = lm.predict(X_train)\n",
    "    y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "    y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "    rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    y_pred_lm = lm.predict(X_test)\n",
    "    y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "    y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "    scores_eval = dict()\n",
    "    scores_eval.update({\"Score Train\":{ \"linear\":lm.score(X_train, y_train),\"ridge\":lm_ridge_cv.score(X_train, y_train),\"lasso\":lm_lasso_cv.score(X_train, y_train)}})\n",
    "    scores_eval.update({\"RMSE Train\":{ \"linear\":rmse(y_train,y_pred_tr_lm),\"ridge\":rmse(y_train,y_pred_tr_ridge),\"lasso\":rmse(y_train,y_pred_tr_lasso)}})\n",
    "    scores_eval.update({\"R2 Test\":{ \"linear\":r2_score(y_test, y_pred_lm),\"ridge\":r2_score(y_test, y_pred_ridge),\"lasso\":r2_score(y_test, y_pred_lasso)}})\n",
    "    scores_eval.update({\"RMSE Test\":{ \"linear\":rmse(y_test, y_pred_lm),\"ridge\":rmse(y_test, y_pred_ridge),\"lasso\":rmse(y_test, y_pred_lasso)}})\n",
    "\n",
    "    data_eval = dict()\n",
    "    \n",
    "    data_eval.update({\"intercept\":{ \"linear\":lm.intercept_,\"ridge\":lm_ridge_cv.intercept_,\"lasso\":lm_lasso_cv.intercept_}})\n",
    "    for idx, col in enumerate(X_df.columns):\n",
    "        data_eval.update({col:{ \"linear\":lm.coef_[idx],\"ridge\":lm_ridge_cv.coef_[idx],\"lasso\":lm_lasso_cv.coef_[idx]}})\n",
    "\n",
    "    ##### Grafico de cada variable sobre el y_target de la prectica train test split###\n",
    "    sns.set(rc={'figure.figsize':(35,4)})\n",
    "    sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True);\n",
    "    ### aca no se que significan los parametros iloc-1 y annot= True (anota los valores dentro de las celdas)\n",
    "\n",
    "    display(pd.DataFrame(data_eval))\n",
    "    display(pd.DataFrame(scores_eval))\n",
    "\n",
    "    retorno = dict()\n",
    "    retorno = { \"linear\": lm, \"ridge\": lm_ridge_cv, \"lasso\": lm_lasso_cv }\n",
    "\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gba = pd.read_csv('df_gba.csv', index_col=0)\n",
    "df_gba = df_gba[(df_gba.surface_total_in_m2.notnull())\n",
    "                  & (df_gba.price_usd_per_m2.notnull())\n",
    "                  & (df_gba.rooms.notnull())\n",
    "                  & (df_gba.provincia.notnull())]\n",
    "df_gba.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_gba = outliers( df = df_gba, criterio = 'provincia', p_z_score = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_gba_norte = df_gba[( df_gba.provincia == 'Bs.As. G.B.A. Zona Norte' )]\n",
    "db_gba_sur = df_gba[( df_gba.provincia == 'Bs.As. G.B.A. Zona Sur' )]\n",
    "db_gba_oeste = df_gba[( df_gba.provincia == 'Bs.As. G.B.A. Zona Oeste' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_gba_norte_dummies = preparar_df_gba( db_gba_norte )\n",
    "\n",
    "db_gba_sur_dummies = preparar_df_gba( db_gba_sur )\n",
    "\n",
    "db_gba_oeste_dummies = preparar_df_gba( db_gba_oeste )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza y separaci√≥n, para el analisis de regresi√≥n vamos a tener:\n",
    "\n",
    "Zona Norte: 8139 filas y 29 columnas\n",
    "\n",
    "Zona Sur: 3153 filas 32 columnas\n",
    "\n",
    "Zona Oeste: 3485 filas y 28 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_norte = df_fit_transform( df = db_gba_norte_dummies, y_val = 'price_usd_per_m2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_sur = df_fit_transform( df = db_gba_sur_dummies, y_val = 'price_usd_per_m2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_oeste = df_fit_transform( df = db_gba_oeste_dummies, y_val = 'price_usd_per_m2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_sur['linear'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Provincia de Buenos Aires](#An√°lisis-de-Propiedades-en-Provincia-de-Buenos-Aires)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de propiedades en Bs As provincia ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov = pd.read_csv('df_bs_as_prov.csv', index_col=0)\n",
    "display(df_bs_as_prov.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_bs_as_prov.sample(10))#elegimos un sample de 10 para que el muestreo sea aleatorio\n",
    "df_bs_as_prov.isnull().sum() # Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_bs_as_prov  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 2: \n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs_as_prov=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov['price_usd_per_m2'].describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2, rooms y localidad.\n",
    "df_bs_as_prov = df_bs_as_prov[(df_bs_as_prov.surface_total_in_m2.notnull())\\\n",
    "                  & (df_bs_as_prov.price_usd_per_m2.notnull())\\\n",
    "                  & (df_bs_as_prov.rooms.notnull())\n",
    "                  & (df_bs_as_prov.localidad.notnull())]\n",
    "df_bs_as_prov.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generamos las dummies para barrios (usando la columna de localidad que es la que contiene dicha informaci√≥n)\n",
    "bs_as_prov_dummies = pd.get_dummies(df_bs_as_prov.localidad, prefix='localidad')\n",
    "bs_as_prov_dummies.columns\n",
    "df_bs_as_prov = pd.concat([df_bs_as_prov, bs_as_prov_dummies], axis=1) #concatenamos las dummies generadas con el df de gba\n",
    "df_bs_as_prov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_bs_as_prov.shape)\n",
    "df_amen_bs_as_prov = df_bs_as_prov['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_bs_as_prov =  df_bs_as_prov['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_bs_as_prov, df_amen2_bs_as_prov], axis=1))\n",
    "plot = (100 * df_bs_as_prov['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el contador de las amenities en Bs As provincia. Decidimos incluirlas como feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n. \n",
    "df_bs_as_prov.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_bs_as_prov.head())\n",
    "display(df_bs_as_prov.shape)\n",
    "display(df_bs_as_prov['price_usd_per_m2'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es1 = df_bs_as_prov[df_bs_as_prov['price_usd_per_m2']>=8000.00]\n",
    "quien_es1 #eliminamos la propiedad ya que es de 20m2 ytiene 7 habitaciones ya creemos que no es posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov.drop(46162, axis=0, inplace=True)\n",
    "display(df_bs_as_prov.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 5942 filas y 89 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresi√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_bs_as_prov = df_bs_as_prov.drop('price_usd_per_m2', axis=1)\n",
    "y_bs_as_prov = df_bs_as_prov.price_usd_per_m2\n",
    "display(X_bs_as_prov.shape)#MODIFIQUE Q ESTABA MAL\n",
    "display(y_bs_as_prov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bs_as_prov, y_bs_as_prov, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Patagonia](#An√°lisis-de-propiedades-en-Patagonia)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de propiedades en Patagonia ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patagonia = pd.read_csv('df_patagonia.csv', index_col=0)\n",
    "display(df_patagonia.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_patagonia.sample(5))#elegimos un sample de 10 para que el muestreo sea aleatorio\n",
    "display(df_patagonia.isnull().sum())\n",
    "display(df_patagonia['price_usd_per_m2'].describe())# Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_patagonia \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard fueron considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patagonia=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_patagonia.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_patagonia['price_usd_per_m2'].describe()  #remoci√≥n correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quienes2 = df_patagonia[df_patagonia['price_usd_per_m2']==10500.00]\n",
    "quienes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Como Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformo dicha columna a variables dummies\n",
    "patagonia_dummies = pd.get_dummies(df_patagonia.provincia, prefix='Provincia_de')\n",
    "patagonia_dummies.columns\n",
    "df_pat = pd.concat([df_patagonia, patagonia_dummies], axis=1) #concatenamos las dummies generadas con el df de patagonia\n",
    "df_pat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amen_pat = df_pat['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_pat =  df_pat['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_pat, df_amen2_pat], axis=1))\n",
    "plot = (100 * df_pat['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n. Saco del df el contador de amenities\n",
    "df_pat.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "df_pat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2,rooms.\n",
    "df_patagonia = df_pat[(df_pat.surface_total_in_m2.notnull())\\\n",
    "                  & (df_pat.price_usd_per_m2.notnull())\\\n",
    "                  & (df_pat.rooms.notnull())]\n",
    "display(df_patagonia.isnull().sum())\n",
    "display(df_patagonia.shape)\n",
    "display(df_patagonia['price_usd_per_m2'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 158 filas y 23 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlaci√≥n en Seaborn usando heatmap\n",
    "\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_patagonia.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresi√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_patagonia = df_patagonia.drop('price_usd_per_m2', axis=1)\n",
    "y_patagonia = df_patagonia.price_usd_per_m2\n",
    "display(X_patagonia.shape)\n",
    "display(y_patagonia.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_patagonia, y_patagonia, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando refacci√≥n\n",
    "df_patagonia.drop(['refaccion'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_patagonia.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Regi√≥n Pampeana](#An√°lisis-de-propiedades-en-Regi√≥n-Pampeana)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de propiedades en la regi√≥n pampeana ###\n",
    "**Nota: No agrupamos a Bs As en este DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pampeana = pd.read_csv('df_pampeana.csv', index_col=0)\n",
    "display(df_pampeana.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_pampeana.sample(5))#elegimos un sample  para que el muestreo sea aleatorio\n",
    "display(df_pampeana.isnull().sum()) # Visualizaci√≥n de las columnas con valores null\n",
    "display(df_pampeana['price_usd_per_m2'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos un super outlier. Empezamos a pensar que hay valores que no estaban en usd sino en pesos y no supimos verlo en el primer desafio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quienes3 = df_pampeana[df_pampeana['price_usd_per_m2']==600000.00] #como tiene rooms en null cuando hagamos el filtro por nulls (que es antes de la regresion) va a desaparecer\n",
    "quienes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_pampeana  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 2: \n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pampeana=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pampeana.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2,rooms y provincia.\n",
    "df_pampeana = df_pampeana[(df_pampeana.surface_total_in_m2.notnull())\\\n",
    "                  & (df_pampeana.price_usd_per_m2.notnull())\\\n",
    "                  & (df_pampeana.rooms.notnull())\\\n",
    "                  & (df_pampeana.provincia.notnull())]\n",
    "df_pampeana.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pampeana['price_usd_per_m2'].describe()  #remoci√≥n correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quien_es4 = df_pampeana[df_pampeana['price_usd_per_m2']==6000.00] #\n",
    "quien_es4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 rooms nunca pueden ocupar 20m2. Procedemos a eliminar esta fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pampeana.drop(40075, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformo dicha columna a variables dummies\n",
    "pampeana_dummies = pd.get_dummies(df_pampeana.provincia, prefix='Provincia_de')\n",
    "pampeana_dummies.columns\n",
    "df_pam = pd.concat([df_pampeana, pampeana_dummies], axis=1) #concatenamos las dummies generadas con el df de patagonia\n",
    "df_pam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_amen_pam = df_pam['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_pam =  df_pam['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_pam, df_amen2_pam], axis=1))\n",
    "plot = (100 * df_pam['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n\n",
    "df_pam.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "df_pam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pam['price_usd_per_m2'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlaci√≥n en Seaborn usando heatmap\n",
    "\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_pam.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 2697 filas y 22 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresi√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_pampeana = df_pam.drop('price_usd_per_m2', axis=1)\n",
    "y_pampeana = df_pam.price_usd_per_m2\n",
    "display(X_pampeana.shape)\n",
    "display(y_pampeana.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pampeana, y_pampeana, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asignamos los alphas y definimos kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 100, 300)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Noroeste](#An√°lisis-de-propiedades-en-Noroeste)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de propiedades en la regi√≥n noroeste ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_noroeste = pd.read_csv('df_noroeste.csv', index_col=0)\n",
    "display(df_noroeste.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_noroeste.sample(10))#elegimos un sample  para que el muestreo sea aleatorio\n",
    "display(df_noroeste.isnull().sum())\n",
    "display(df_noroeste['price_usd_per_m2'].describe())# Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quien_es5 = df_noroeste[df_noroeste['price_usd_per_m2']>=5400] #Esta propiedad tiene rooms en nan (y ya hicimos el regex en titulo y descripcion y sabemos que no hay info). Va a ser eliminada mas abajo con los nulls\n",
    "quien_es5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_noroeste  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noroeste=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_noroeste.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformo dicha columna a variables dummies\n",
    "noroeste_dummies = pd.get_dummies(df_noroeste.provincia, prefix='Provincia_de')\n",
    "noroeste_dummies.columns\n",
    "df_noroeste = pd.concat([df_noroeste, noroeste_dummies], axis=1) #concatenamos las dummies generadas con el df de patagonia\n",
    "df_noroeste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2 y rooms \n",
    "df_noroeste = df_noroeste[(df_noroeste.surface_total_in_m2.notnull())\\\n",
    "                  & (df_noroeste.price_usd_per_m2.notnull())\\\n",
    "                  & (df_noroeste.rooms.notnull())]\n",
    "df_noroeste.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n\n",
    "df_noroeste.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_noroeste.head())\n",
    "display(df_noroeste['price_usd_per_m2'].describe())\n",
    "display(df_noroeste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza, quedan muy pocos datos y para el analisis de regresi√≥n vamos a tener 30 filas y 24 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlaci√≥n en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_noroeste.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos refacci√≥n, PH, store, barrio cerrado, vigilancia y las provincias de Jujuy y La Rioja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando las variables irrelevantes\n",
    "df_noroeste.drop(['refaccion', 'store', 'PH', 'vigilancia', 'barrio_cerrado', 'Provincia_de_Jujuy',\n",
    "                  'Provincia_de_La Rioja'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlaci√≥n en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_noroeste.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresi√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_noroeste = df_noroeste.drop('price_usd_per_m2', axis=1)\n",
    "y_noroeste = df_noroeste.price_usd_per_m2\n",
    "display(X_noroeste.shape)\n",
    "display(y_noroeste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_noroeste, y_noroeste, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asignamos los alphas\n",
    "alphas = np.linspace(0.1, 100, 300)\n",
    "\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\",size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Nordeste](#An√°lisis-de-propiedades-en-Nordeste)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de propiedades en la regi√≥n nordeste ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nordeste = pd.read_csv('df_nordeste.csv', index_col=0)\n",
    "display(df_nordeste.shape) #Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_nordeste.sample(10))#elegimos un sample  para que el muestreo sea aleatorio\n",
    "display(df_nordeste.isnull().sum())\n",
    "display(df_nordeste['price_usd_per_m2'].describe())# Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_nordeste  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nordeste=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nordeste.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nordeste['price_usd_per_m2'].describe()  #remoci√≥n correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es5 = df_nordeste[df_nordeste['price_usd_per_m2']>=7000] #Es posible que esta propiedad este bien cotizada en Puerto Iguazu que es una zona turistica\n",
    "quien_es5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#como Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformamos dicha columna a variables dummies\n",
    "nordeste_dummies = pd.get_dummies(df_nordeste.provincia, prefix='Provincia')\n",
    "nordeste_dummies.columns\n",
    "df_nord = pd.concat([df_nordeste, nordeste_dummies], axis=1) #concatenamos las dummies generadas con el df de la region Nordeste\n",
    "df_nord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresi√≥n\n",
    "df_nord.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "df_nord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amen_nord = df_nordeste['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_nord =  df_nordeste['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_nord, df_amen2_nord ], axis=1))\n",
    "plot = (100 * df_nord['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2,rooms.\n",
    "df_nordeste = df_nord[(df_nord.surface_total_in_m2.notnull())\\\n",
    "                  & (df_nord.price_usd_per_m2.notnull())\\\n",
    "                  & (df_nord.rooms.notnull())]\n",
    "display(df_nordeste.isnull().sum())\n",
    "display(df_nordeste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 268 filas y 23 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de correlaci√≥n en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (25, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_nordeste.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_nordeste = df_nordeste.drop('price_usd_per_m2', axis=1)\n",
    "y_nordeste = df_nordeste.price_usd_per_m2\n",
    "display(X_nordeste.shape)\n",
    "display(y_nordeste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nordeste, y_nordeste, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando las variables irrelevantes\n",
    "df_nordeste.drop(['refaccion', 'store', 'Provincia_Formosa'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Propiedades en Cuyo](#An√°lisis-de-propiedades-en-Cuyo)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  An√°lisis de propiedades en la regi√≥n de Cuyo ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cuyo = pd.read_csv('df_cuyo.csv', index_col=0)\n",
    "display(df_cuyo.shape) #Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_cuyo.sample(10))#selecci√≥n de 10 ejemplares al azar\n",
    "display(df_cuyo.isnull().sum())\n",
    "display(df_cuyo['price_usd_per_m2'].describe())# Visualizaci√≥n de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_cuyo  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuyo=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cuyo.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuyo['price_usd_per_m2'].describe()  #remoci√≥n correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuyo_dummies = pd.get_dummies(df_cuyo.provincia, prefix='Provincia')\n",
    "df_cuyo = pd.concat([df_cuyo, cuyo_dummies], axis=1) \n",
    "display(df_cuyo.shape)\n",
    "display(df_cuyo.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuyo = df_cuyo[(df_cuyo.surface_total_in_m2.notnull())\\\n",
    "                  & (df_cuyo.price_usd_per_m2.notnull())\\\n",
    "                  & (df_cuyo.rooms.notnull())]\n",
    "display(df_cuyo.shape)\n",
    "display(df_cuyo.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay pocas propiedades en la regi√≥n de Cuyo despu√©s de la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amen_cuyo = df_cuyo['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_cuyo =  df_cuyo['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_cuyo, df_amen2_cuyo], axis=1))\n",
    "plot = (100 * df_cuyo['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las colamumnas que no van a ser utilizadas para la regresi√≥n\n",
    "df_cuyo.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', 'price_aprox_usd',\n",
    "            'pileta', 'parrilla', 'gimnasio', 'sauna', 'laundry', 'playroom', 'sum', 'sala_reuniones', \n",
    "            'restaurant', 'quincho',], inplace=True, axis=1)\n",
    "display(df_cuyo.shape)\n",
    "display(df_cuyo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de esta limpieza, para el analisis de regresi√≥n vamos a tener 44 filas y 22 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de correlaci√≥n en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "sns.set(font_scale=1.3)\n",
    "sns.heatmap(df_cuyo.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estrenar, en refacci√≥n o normal no parecen estar aportando datos a la correlaci√≥n. Tampoco vigilancia, PH y la provincia de San Juan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando las variables irrelevantes\n",
    "df_cuyo.drop(['vigilancia', 'estrenar','refaccion', 'Provincia_San Juan', 'normal', 'PH'], axis=1, inplace=True)\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (25, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_cuyo.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_cuyo.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_cuyo.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El ùõº estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El ùõº estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size = 12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size = 12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [An√°lisis de Sample en CABA](#An√°lisis-de-Sample-en-CABA)\n",
    "[Volver](#√çndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el Dataframe de los 100 Samples de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba_sample = pd.read_csv('caba_sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos un Dataframe por cada tipo de Propiedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph_sample = df_caba_sample[(df_caba_sample.PH== 1)]\n",
    "df_apartment_sample = df_caba_sample[(df_caba_sample.apartment== 1)]\n",
    "df_store_sample = df_caba_sample[(df_caba_sample.store== 1)]\n",
    "df_house_sample = df_caba_sample[(df_caba_sample.house== 1)]\n",
    "\n",
    "df_ph_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "df_apartment_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "df_store_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "df_house_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion a utilizar para predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_sample_caba( df, scaler, linear_model, ridge_model, lasso_model ):\n",
    "    # definimos X e y\n",
    "    X_df = df.drop('price_usd_per_m2', axis=1)\n",
    "    y_df = df.price_usd_per_m2\n",
    "\n",
    "    # Escalamos los valores con el escalador fiteado al momento de armar el Modelo, para cada tipo de propiedad,\n",
    "    # ya que los modelos fueron entrenados con los valores escalados.\n",
    "    X_df = scaler.transform(X_df)\n",
    "\n",
    "    # Predecimos con modelo lineal\n",
    "    y_pred_lm = linear_model.predict(X_df)\n",
    "    \n",
    "    # Predecimos con Ridge\n",
    "    y_pred_ridge = ridge_model.predict(X_df)\n",
    "    \n",
    "    # Predecimos con Lasso\n",
    "    y_pred_lasso = lasso_model.predict(X_df)\n",
    "\n",
    "    ### Visualizamos y comparamos los valores de cada predictor con el real del dataframe original ###\n",
    "    lista = list()\n",
    "    for idx, val in enumerate( X_df ):\n",
    "      lista.append( { \"real\": y_df.iloc[ idx ], \"linear\": y_pred_lm[ idx ], \"ridge\":y_pred_ridge[ idx ], \"lasso\":y_pred_lasso[ idx ] } )\n",
    "\n",
    "    df_retorno = pd.DataFrame(lista)\n",
    "    display(df_retorno)\n",
    "    return df_retorno\n",
    "    #############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ph = prediccion_sample_caba( df = df_ph_sample, scaler = scaler_ph, linear_model = modelo_lr_ph, ridge_model = modelo_ridge_ph, lasso_model = modelo_lasso_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(pred_ph.real,pred_ph.real, label='Real')\n",
    "plt.scatter(pred_ph.linear, pred_ph.real, s=100, c='r', marker='o', zorder=10, label='Lineal')\n",
    "plt.scatter(pred_ph.ridge, pred_ph.real, s=100, c='g', marker='+', zorder=10, label='Ridge')\n",
    "plt.scatter(pred_ph.lasso, pred_ph.real, s=100, c='purple', marker='v', zorder=10, label='Lasso')\n",
    "plt.xlabel(\"Predicciones \", size=12)\n",
    "plt.ylabel(\"Valores reales PH precio en USD por m2\", size=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de Apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_ap = prediccion_sample_caba( df = df_apartment_sample, scaler = scaler_ap, linear_model = modelo_lr_ap, ridge_model = modelo_ridge_ap, lasso_model = modelo_lasso_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ap = pred_ap[ (pred_ap.real < 21085) ]\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(pred_ap.real,pred_ap.real, label='Real')\n",
    "plt.scatter(pred_ap.linear, pred_ap.real, s=100, c='r', marker='o', zorder=10, alpha=0.3, label='Lineal')\n",
    "plt.scatter(pred_ap.ridge, pred_ap.real, s=200, c='g', marker='+', zorder=10, label='Ridge')\n",
    "plt.scatter(pred_ap.lasso, pred_ap.real, s=100, c='purple', marker='v', zorder=10, alpha=0.3, label='Lasso')\n",
    "plt.xlabel(\"Predicciones \", size=12)\n",
    "plt.ylabel(\"Valores reales Apartment precio en USD por m2\", size=12)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ho = prediccion_sample_caba( df = df_house_sample, scaler = scaler_ho, linear_model = modelo_lr_ho, ridge_model = modelo_ridge_ho, lasso_model = modelo_lasso_ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de House\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(pred_ho.real,pred_ho.real, label='Real')\n",
    "plt.scatter(pred_ho.linear, pred_ho.real, s=100, c='r', marker='o', zorder=10, label='Lineal')\n",
    "plt.scatter(pred_ho.ridge, pred_ho.real, s=100, c='g', marker='+', zorder=10, label='Ridge')\n",
    "plt.scatter(pred_ho.lasso, pred_ho.real, s=100, c='purple', marker='v', zorder=10, label='Lasso')\n",
    "plt.xlabel(\"Predicciones \", size=12)\n",
    "plt.ylabel(\"Valores reales House precio en USD por m2\", size=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para store solo tiene una propiedad y no hicimos el grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediccion_sample_caba( df = df_store_sample, scaler = scaler_st, linear_model = modelo_lr_st, ridge_model = modelo_ridge_st, lasso_model = modelo_lasso_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
