{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 2. Prediciendo precios de propiedades\n",
    "\n",
    "**Grupo 2:**\n",
    "\n",
    "Faro, Gonzalo\n",
    "\n",
    "Cabrol, Angelica\n",
    "\n",
    "Vinyolas, Mariana\n",
    "\n",
    "Hutler, Ianina\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Índice](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Objetivos](#Objetivos)\n",
    "- [Indicaciones](#Indicaciones)\n",
    "- [Importación de librerías](#Importación-de-librerías)\n",
    "- [Seteos Generales](#Seteos-Generales)\n",
    "- [Feature Selection](#Feature-Selection)\n",
    "- [Análisis de propiedades en Argentina](#Análisis-de-Propiedades-en-Argentina)\n",
    "- [Análisis de propiedades en CABA](#Análisis-de-Propiedades-en-CABA)\n",
    "- [Análisis de propiedades en GBA](#Análisis-de-Propiedades-en-GBA)\n",
    "- [Análisis de propiedades en Provincia De Buenos Aires](#Análisis-de-Propiedades-en-Provincia-de-Buenos-Aires)\n",
    "- [Análisis de propiedades en Patagonia](#Análisis-de-Propiedades-en-Patagonia)\n",
    "- [Análisis de propiedades en Región Pampeana](#Análisis-de-Propiedades-en-Región-Pampeana)\n",
    "- [Análisis de propiedades en Noroeste](#Análisis-de-Propiedades-en-Noroeste)\n",
    "- [Análisis de propiedades en Nordeste](#Análisis-de-Propiedades-en-Nordeste)\n",
    "- [Análisis de propiedades en Cuyo](#Análisis-de-Propiedades-en-Cuyo)\n",
    "- [Análisis de Sample en CABA](#Análisis-de-Sample-en-CABA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Objetivos](#Objetivos)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivos:\n",
    "\n",
    "● Estimar un modelo de regresión lineal que realice predicciones para el precio por metro cuadrado. Deberá prestar cierta atención a la estructura espacial de los precios.\n",
    "\n",
    "● Aplicar regularización a modelos lineales (pueden hacerlo para obtener un puntaje adicional). La idea es la siguiente: estimar una regresión Ridge y una LASSO sobre el dataset. Para ello, deberán usar cross-validation para tunear el parámetro de regularización que maximiza R2 en tu test set. ¿Cómo son las performances entre los modelos regularizados y no regularizado? ¿Cuál funciona mejor? ¿Qué hace una regresión Ridge? ¿Y una LASSO?¿Qué diferencias hay con la regresión lineal sin regularizar?\n",
    "\n",
    "● Seleccionar mediante muestreo aleatorio simple una submuestra de 100 propiedades. Este será su portafolio de departamentos. En base al mejor modelo que haya encontrado determine cuáles de los departamentos, tanto en su portafolio como fuera de él, se encuentran sobrevaluados o subvaluados y en qué magnitud.\n",
    "\n",
    "● Teniendo en cuenta que podría comprar y vender propiedades al precio de mercado, omitamos costos de transacción, con un capital inicial igual al valor de mercado de las propiedades en su portafolio. ¿Cuál es el mejor portafolio de propiedades que podría comprar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Indicaciones](#Indicaciones)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trabajo se organizará de la siguiente manera:\n",
    "\n",
    "1- Análisis de propiedades en Argentina.\n",
    "\n",
    "2- Análisis de propiedades en CABA.\n",
    "\n",
    "2.1 Análisis de propiedades en CABA por tipo de propiedad.\n",
    "\n",
    "3- Análisis de propiedades en el Gran Buenos Aires (gba).\n",
    "\n",
    "4- Análisis de propiedades en Bs As provincia.\n",
    "\n",
    "5- Análisis de propiedades en Patagonia.\n",
    "\n",
    "6- Análisis de propiedades en la región pampeana.\n",
    "\n",
    "7- Análisis de propiedades en la región noroeste.\n",
    "\n",
    "8- Análisis de propiedades en la región nordeste. \n",
    "\n",
    "9- Análisis de propiedades en la región de Cuyo.\n",
    "\n",
    "10- Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Importación de librerías](#Importación-de-librerías)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos los diferentes paquetes a utilizar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Seteos Generales](#Seteos-Generales)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteos generales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Feature Selection](#Feature-Selection)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection:**\n",
    "\n",
    "Para predecir el precio por metro cuadrado de las propiedades de Argentina seleccionamos como relevantes las siguientes features: tamaño de la propiedad (superficie total en m2), el tipo de propiedad (PH, departamento, negocio o casa), cantidad de ambientes (rooms), ubicación (barrio, provincia o localidad), amenities (pileta, parrila, gimnasio, sauna, laundry, playroom, sum, sala de reuniones, restaurant y quincho), si tiene o no superficie descubierta (terraza, balcón o patio), si tiene o no expensas, si tiene garage o cochera, si tiene o no vigilancia, si tiene o no dependencia, si es a estrenar, en refacción o normal (ninguna de las dos anteriores) y si se encuentra en un barrio cerrado o country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Argentina](#Análisis-de-Propiedades-en-Argentina)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de propiedades en Argentina. ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargamos el DataFrame de Argentina**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arg = pd.read_csv('df_total.csv', index_col=0)\n",
    "display(df_arg.shape) # Nos fijamos cuantas filas y columnas tiene\n",
    "display(df_arg.sample(10)) # Selección de 10 ejemplares al azar para su observación\n",
    "display(df_arg.isnull().sum()) # Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es = df_arg[df_arg['surface_total_in_m2']<=15]\n",
    "quien_es['surface_total_in_m2'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas geonames_id, lat-lon, lat, lon, price_aprox_usd, localidad y barrio no van a ser utilizadas. \n",
    "La columna de provincia es la que vamos a utilizar para crear dummies y no tiene ningun valor null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos Variables Dummies para las provincias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prov_dummies = pd.get_dummies(df_arg.provincia, prefix='Provincia')\n",
    "df_arg = pd.concat([df_arg, prov_dummies], axis=1) \n",
    "display(df_arg.shape)\n",
    "display(df_arg.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las filas con valores nan para surface_total_in_m2, price_usd_per_m y rooms que son las que voy a conservar para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg = df_arg[(df_arg.surface_total_in_m2.notnull())\\\n",
    "                  & (df_arg.price_usd_per_m2.notnull())\\\n",
    "                  & (df_arg.rooms.notnull())]\n",
    "display(df_arg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de la columna amenities**\n",
    "\n",
    "Recuperamos por regex las siguientes amenities: pileta, parrilla, gimnasio, sauna, laundry, playroom, sum, sala de reuniones, restaurant y quincho. Creamos un contador y vemos con cuantos amenities cuenta la propiedad. Decidimos entonces eliminar las amenities por separado y quedarnos con el contador. A continuación también eliminamos el resto de las columnas que no va a participar en el análisis. Esto se repetirá en todas las regiones de Argentina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', 'price_aprox_usd', 'pileta', \n",
    "         'parrilla', 'gimnasio', 'sauna', 'expenses', 'laundry', 'playroom', 'sum', 'sala_reuniones', 'restaurant',\n",
    "         'quincho'], inplace=True, axis=1)\n",
    "display(df_arg.shape)\n",
    "display(df_arg.sample(5))\n",
    "display(df_arg.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Después de esta limpieza, para el analisis de regresión vamos a tener 41217 filas y 47 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_arg.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_arg.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos para train y test utilizando la función de Scikit-learn que se encarga de la separación entre test y entrenamiento. Seteamos el parámetro test_size en 0.3 que será la propoción de los datos que vamos a separar para hacer la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante estandarizar todos los regresores antes de ejecutar una regresión Ridge y Lasso. Así ya no están en unidades físicas sino en unidades de su propio desvío estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sobre el set de entrenamiento (Train Set)***\n",
    "\n",
    "Proceso de Tunning de los Hiperparámetros: Asignamos los alphas y definimos kfold como estrategia de cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.1, 10000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el Score de entrenamiento de cada modelo.\n",
    "El coeficiente de determinación, denominado R² representa cuánta varianza explica el modelo del total de varianza existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que apesar de que el R2 es muy bajo, mejora levemente con el test y el RMSE baja. Vamos a probar el mismo procedimiento eliminando outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observación de outliers en Argentina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "import seaborn as sns\n",
    "sns.boxplot(x=df_arg['price_usd_per_m2']) #observación de los outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arg['price_usd_per_m2'].describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el cuantil 75 es razonable pero hay un maximo de $ 540.000 que podriamos filtrar para ver si el modelo mejora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg_out = pd.read_csv('df_total.csv', index_col=0) #importo nuevamente el archivo de argentina bajo otro nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_arg_out \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 2: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 2:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos el procedimiento: Generamos Variables Dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prov_dummies = pd.get_dummies(df.provincia, prefix='Provincia')\n",
    "df = pd.concat([df, prov_dummies], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.surface_total_in_m2.notnull())\\\n",
    "        & (df.price_usd_per_m2.notnull())\\\n",
    "        & (df.rooms.notnull())]\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['price_usd_per_m2'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es = df[df['price_usd_per_m2']>=20000] \n",
    "quien_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', 'price_aprox_usd', 'pileta', \n",
    "         'parrilla', 'gimnasio', 'sauna', 'expenses', 'laundry', 'playroom', 'sum', 'sala_reuniones', 'restaurant',\n",
    "         'quincho'],inplace=True, axis=1)\n",
    "display(df.shape)\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42) # Separamos los datos para train y test\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.01, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el Score de entrenamiento de cada modelo y observamos nuevamente el R² y RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión:**\n",
    "Luego de aplicar el filtro de los outliers tanto R2 como  RMSE se mantuvieron con el mismo valor aproximadamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Análisis de Propiedades en CABA](#Análisis-de-propiedades-en-CABA)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Análisis de propiedades en CABA. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargamos el DataFrame de CABA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_caba = pd.read_csv('df_caba.csv', index_col=0)\n",
    "display(df_caba.shape) #Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_caba.sample(10)) #Seleccionamos un sample de 10 para que el muestreo sea aleatorio\n",
    "display(df_caba.isnull().sum())#Verificamos si hay valores faltantes\n",
    "display(df_caba['price_usd_per_m2'].describe()) #Observamos los estadisticos para la columna price_usd_per_m2 para ver posibles outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que en el DataFrame de Argentina el modelo de regresión mejoró gracias a eliminar algunos outliers decidimos implementar lo mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_caba\n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['outlier'], inplace=True, axis=1)\n",
    "df_caba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas geonames_id, lat-lon, lat, lon, price_aprox_usd, provincia y barrio no van a ser utilizadas. \n",
    "La columna de localidad es la que vamos a utilizar para crear dummies y no tiene ningun valor null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las filas con valores nan para surface_total_in_m2, price_usd_per_m2,rooms y localidad que son las que voy a conservar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_caba = df_caba[(df_caba.surface_total_in_m2.notnull())\\\n",
    "                  & (df_caba.price_usd_per_m2.notnull())\\\n",
    "                  & (df_caba.rooms.notnull())\\\n",
    "                  & (df_caba.localidad.notnull())]\n",
    "display(df_caba.shape)\n",
    "display(df_caba.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Como son muchas las dummies de amenities las eliminamos solo para ver el heatmap, dejando el contador amenities ####\n",
    "\n",
    "df_heatmap = df_caba.drop(['amenities', 'geonames_id', 'lat-lon', 'lat','lon', 'provincia', 'barrio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (40, 25)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_heatmap.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos variables dummies para los barrios de CABA. (dicha información viene contenida en la columna localidad).\n",
    "Luego unimos estas dummies con el DataFrame de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrios_dummies = pd.get_dummies(df_caba.localidad, prefix='barrio')\n",
    "df_caba = pd.concat([df_caba, barrios_dummies], axis=1) \n",
    "df_caba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_caba.head())\n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, las columnas que vamos a utilizar son: surface_total_in_m2, price_usd_per_m2, rooms, terraza, balcón, patio, expensas, barrio_cerrado (que también incluye country),vigilancia, si tiene dependencia (habitación de servicio), estrenar, normal, refacción y cochera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos un dataframe, en lugar de obtener el sample, para asegurarnos que haya al menos un registro\n",
    "# por cada tipo de propiedad. Para generar una muestra en el momento, descomentar las siguientes 3 lineas\n",
    "# y comentar las ultimas 2\n",
    "# df_sample = df_caba.sample(100)\n",
    "# df_caba = df_caba.drop( df_sample.index)\n",
    "# df_sample.to_csv('caba_sample.csv')\n",
    "\n",
    "df_sample = pd.read_csv('caba_sample.csv', index_col=0)\n",
    "df_caba = df_caba.drop( df_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_caba.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_caba.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probamos los resultados sacando outliers y dividiendo por tipo de propiedad en CABA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba = pd.read_csv('df_caba.csv', index_col=0) #Cargamos el df de CABA nuevamente \n",
    "df_caba = df_caba[(df_caba.surface_total_in_m2.notnull())\\\n",
    "                  & (df_caba.price_usd_per_m2.notnull())\\\n",
    "                  & (df_caba.rooms.notnull())\\\n",
    "                  & (df_caba.localidad.notnull())]\n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analizamos las propiedades de Boedo\n",
    "df_boedo = df_caba[(df_caba.localidad == 'Boedo')]\n",
    "df_boedo.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se verifica que muchas de las propiedades tienen en precio en ARS, las pasamos a USD\n",
    "df_boedo.price_usd_per_m2 = df_boedo.price_usd_per_m2.apply( lambda x: x / 17.6445 if x > 7000 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boedo.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba = df_caba[(df_caba.localidad != 'Boedo')]\n",
    "df_caba = pd.concat([df_caba, df_boedo], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos las propiedades de San Cristobal\n",
    "df_sancri = df_caba[(df_caba.localidad == 'San Cristobal')]\n",
    "df_sancri.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_sancri.price_usd_per_m2 > 7000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se verifica que muchas de las propiedades tienen en precio en ARS, las pasamos a USD\n",
    "df_sancri.price_usd_per_m2 = df_sancri.price_usd_per_m2.apply( lambda x: x / 17.6445 if x > 7000 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sancri.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba = df_caba[(df_caba.localidad != 'San Cristobal')]\n",
    "df_caba = pd.concat([df_caba, df_sancri], ignore_index=True)\n",
    "df_caba.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos una funcion para eliminar Outliers\n",
    "df=df_caba\n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generamos variables dummies para los barrios de CABA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrios_dummies = pd.get_dummies(df_caba.localidad, prefix='barrio')\n",
    "df_caba = pd.concat([df_caba, barrios_dummies], axis=1) \n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no vamos a utilzar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_caba.head())\n",
    "display(df_caba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separamos el df según el tipo de propiedad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph = df_caba[(df_caba.PH== 1)]\n",
    "df_ph.drop(['apartment', 'store', 'house', 'PH'], inplace=True, axis=1)\n",
    "df_apartment = df_caba[(df_caba.apartment== 1)]\n",
    "df_apartment.drop(['PH', 'store', 'house', 'apartment'], inplace=True, axis=1)\n",
    "df_store = df_caba[(df_caba.store== 1)]\n",
    "df_store.drop(['PH', 'apartment', 'house','store'], inplace=True, axis=1)\n",
    "df_house = df_caba[(df_caba.house== 1)]\n",
    "df_house.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "\n",
    "display(df_ph.head())\n",
    "display(df_ph.shape)\n",
    "display(df_apartment.head())\n",
    "display(df_apartment.shape)\n",
    "display(df_store.head())\n",
    "display(df_store.shape)\n",
    "display(df_house.head())\n",
    "display(df_house.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelos de Regresión**\n",
    "\n",
    "\n",
    "Tipo de Propiedad: 'PH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_ph.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_ph.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ph = StandardScaler() #estandarizamos los datos\n",
    "X_train = scaler_ph.fit_transform(X_train)\n",
    "X_test = scaler_ph.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.1, 100, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_ph = lm.fit(X_train, y_train)\n",
    "modelo_ridge_ph = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_ph = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", fontsize='small')\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", fontsize='small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes para cada modelo: 'PH' Intercept y coef de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de LM para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada feature y los coef calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tipo de Propiedad: 'APARTMENT'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_apartment.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_apartment.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ap = StandardScaler() #estandarizamos\n",
    "X_train = scaler_ap.fit_transform(X_train)\n",
    "X_test = scaler_ap.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.01, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_ap = lm.fit(X_train, y_train)\n",
    "modelo_ridge_ap = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_ap = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes para cada modelo: 'APARTMENT' Intercept y coef de cada feature (fichur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos los coeficientes de LM para cada feature en PH\n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada fichur y los coef calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True, cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de Propiedad: 'HOUSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos X e y\n",
    "X_df = df_house.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_house.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ho = StandardScaler()\n",
    "X_train = scaler_ho.fit_transform(X_train)\n",
    "X_test = scaler_ho.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_ho = lm.fit(X_train, y_train)\n",
    "modelo_ridge_ho = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_ho = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de LM para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada feature y los coeficientes calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True, cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de Propiedad: 'STORE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos X e y\n",
    "X_df = df_store.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_store.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_st = StandardScaler()\n",
    "X_train = scaler_st.fit_transform(X_train)\n",
    "X_test = scaler_st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr_st = lm.fit(X_train, y_train)\n",
    "modelo_ridge_st = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso_st = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de la muestra\n",
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes para cada modelo: 'STORE' Intercept y coef de cada feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Regresion Lineal  ####\n",
    "print (lm.intercept_)\n",
    "lm_coefs = list(zip(X_df.columns, lm.coef_))\n",
    "lm_coefs =  sorted(lm_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de LM\n",
    "lm_coefs = pd.DataFrame(lm_coefs, columns=('Features', 'LM_Coef'))\n",
    "lm_coefs = lm_coefs.set_index('Features')\n",
    "lm_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####  Ridge con CV  ####\n",
    "print (lm_ridge_cv.intercept_)\n",
    "ridge_coefs = list(zip(X_df.columns, lm_ridge_cv.coef_))\n",
    "ridge_coefs = sorted(ridge_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Ridge\n",
    "ridge_coefs = pd.DataFrame(ridge_coefs, columns=('Features','Ridge_Coef'))\n",
    "ridge_coefs = ridge_coefs.set_index('Features')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  LASSO con CV  ####\n",
    "print (lm_lasso_cv.intercept_)\n",
    "lasso_coefs = list(zip(X_df.columns, lm_lasso_cv.coef_))\n",
    "lasso_coefs = sorted(lasso_coefs, key=lambda x:x[1], reverse=True)\n",
    "# armamos un df con los coeficientes de Lasso\n",
    "lasso_coefs = pd.DataFrame(lasso_coefs, columns=('Features','Lasso_Coef'))\n",
    "lasso_coefs = lasso_coefs.set_index('Features')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de LM para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lm_coefs['LM_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Ridge para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "ridge_coefs['Ridge_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteamos los coeficientes de Lasso para cada feature \n",
    "sns.set(rc={'figure.figsize':(20,8)})\n",
    "lasso_coefs['Lasso_Coef'].plot(kind='bar', color=sns.color_palette(n_colors=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimimos un heatmap para evaluar las correlaciones de cada fichur y los coef calculados con el target\n",
    "sns.set(rc={'figure.figsize':(35,4)})\n",
    "sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True, cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en GBA](#Análisis-de-propiedades-en-GBA)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de propiedades en el Gran Buenos Aires (gba) ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gba = pd.read_csv('df_gba.csv', index_col=0)\n",
    "display(df_gba.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_gba.sample(5))#elegimos un sample de 10 para que el muestreo sea aleatorio\n",
    "df_gba.isnull().sum()# Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2 y rooms.\n",
    "df_gba = df_gba[(df_gba.surface_total_in_m2.notnull())\n",
    "                  & (df_gba.price_usd_per_m2.notnull())\n",
    "                  & (df_gba.rooms.notnull())\n",
    "                  & (df_gba.localidad.notnull())]\n",
    "df_gba.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generamos las dummies para barrios (usando la columna de localidad que es la que contiene dicha información)\n",
    "gba_dummies = pd.get_dummies(df_gba.localidad, prefix='barrio')\n",
    "gba_dummies.columns\n",
    "df_gba = pd.concat([df_gba, gba_dummies], axis=1) #concatenamos las dummies generadas con el df de gba\n",
    "df_gba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Eliminamos las columnas que no van a ser utilizadas para la regresión. \n",
    "df_gba.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_gba.sample(5))\n",
    "display(df_gba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza, para el analisis de regresión vamos a tener 15212 filas y  51 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# definimos X e y\n",
    "X_gba = df_gba.drop('price_usd_per_m2', axis=1)\n",
    "y_gba = df_gba.price_usd_per_m2\n",
    "display(X_gba.shape)\n",
    "display(y_gba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gba, y_gba, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asignamos los alphas\n",
    "alphas = np.linspace(0.1, 10000, 300)\n",
    "\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir por región del GBA para ver si estos resultados mejoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_df_gba( df_param ):\n",
    "    #generamos las dummies para barrios (usando la columna de localidad que es la que contiene dicha información)\n",
    "    gba_dummies = pd.get_dummies(df_param.localidad, prefix='barrio')\n",
    "    gba_dummies.columns\n",
    "    df_retorno = pd.concat([df_param, gba_dummies], axis=1) #concatenamos las dummies generadas con el df de gba\n",
    "\n",
    "    # #Eliminamos las columnas que no van a ser utilizadas para la regresión. Saco del df el contador de amenities\n",
    "    df_retorno.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "                 'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "                 'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "                  inplace=True, axis=1)\n",
    "    display(df_retorno.sample(5))\n",
    "    display(df_retorno.shape)\n",
    "    return df_retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers( df, criterio, p_z_score ):\n",
    "    criterios = df[ criterio ].unique()\n",
    "    for x in criterios:\n",
    "           mean_1 = np.mean( df.price_usd_per_m2[ ( df[ criterio ] ==x ) ] )\n",
    "           std_1 = np.std( df.price_usd_per_m2[ ( df[ criterio ] ==x ) ] )\n",
    "           mean_2 = np.mean( df.surface_total_in_m2[ ( df[ criterio ] == x ) ] )\n",
    "           std_2 = np.std( df.surface_total_in_m2[ ( df[ criterio ] == x ) ] )\n",
    "\n",
    "           for index2, y in df[ ( df[ criterio ] == x ) ].iterrows():\n",
    "                   if( std_1 != 0 ):\n",
    "                       z_score = ( y.price_usd_per_m2 - mean_1 )/std_1\n",
    "                       if np.abs( z_score ) > p_z_score:\n",
    "                           df.loc[ index2, 'outlier' ] = \"YES\"\n",
    "                   if( std_2 != 0 ):\n",
    "                       z_score2= ( y.surface_total_in_m2 - mean_2 )/std_2\n",
    "                       if np.abs( z_score2 ) > p_z_score:\n",
    "                           df.loc[ index2, 'outlier' ]=\"YES\"\n",
    "\n",
    "    df = df[(df.outlier!='YES')]\n",
    "    df.drop(['outlier'],inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fit_transform( df, y_val ):\n",
    "    # Zona Norte\n",
    "    # definimos X e y\n",
    "    X_df = df.drop(y_val, axis=1)\n",
    "    y_df = df[ y_val ]\n",
    "    display(X_df.shape)\n",
    "    display(y_df.shape)\n",
    "\n",
    "    # separamos los datos para train y test\n",
    "    X_train_no_norm, X_test_no_norm, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "    print(X_train_no_norm.shape, y_train.shape)\n",
    "    print(X_test_no_norm.shape, y_test.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_no_norm) \n",
    "    X_test = scaler.transform(X_test_no_norm)\n",
    "\n",
    "    #asignamos los alphas\n",
    "    alphas = np.linspace(0.1, 1000, 300)\n",
    "\n",
    "    # Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=68)\n",
    "\n",
    "    #Instanciamos los modelos \n",
    "    lm = LinearRegression()\n",
    "    lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "    lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)\n",
    "\n",
    "    # Entrenamos los modelos\n",
    "    modelo_lr = lm.fit(X_train, y_train)\n",
    "    modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "    modelo_lasso = lm_lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "    #Imprimimos el alpha que eligio para cada modelo\n",
    "    print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "          'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')\n",
    "\n",
    "    # Calculamos el RMSE\n",
    "\n",
    "    y_pred_tr_lm = lm.predict(X_train)\n",
    "    y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "    y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "    rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    y_pred_lm = lm.predict(X_test)\n",
    "    y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "    y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "    scores_eval = dict()\n",
    "    scores_eval.update({\"Score Train\":{ \"linear\":lm.score(X_train, y_train),\"ridge\":lm_ridge_cv.score(X_train, y_train),\"lasso\":lm_lasso_cv.score(X_train, y_train)}})\n",
    "    scores_eval.update({\"RMSE Train\":{ \"linear\":rmse(y_train,y_pred_tr_lm),\"ridge\":rmse(y_train,y_pred_tr_ridge),\"lasso\":rmse(y_train,y_pred_tr_lasso)}})\n",
    "    scores_eval.update({\"R2 Test\":{ \"linear\":r2_score(y_test, y_pred_lm),\"ridge\":r2_score(y_test, y_pred_ridge),\"lasso\":r2_score(y_test, y_pred_lasso)}})\n",
    "    scores_eval.update({\"RMSE Test\":{ \"linear\":rmse(y_test, y_pred_lm),\"ridge\":rmse(y_test, y_pred_ridge),\"lasso\":rmse(y_test, y_pred_lasso)}})\n",
    "\n",
    "    data_eval = dict()\n",
    "    \n",
    "    data_eval.update({\"intercept\":{ \"linear\":lm.intercept_,\"ridge\":lm_ridge_cv.intercept_,\"lasso\":lm_lasso_cv.intercept_}})\n",
    "    for idx, col in enumerate(X_df.columns):\n",
    "        data_eval.update({col:{ \"linear\":lm.coef_[idx],\"ridge\":lm_ridge_cv.coef_[idx],\"lasso\":lm_lasso_cv.coef_[idx]}})\n",
    "\n",
    "    ##### Grafico de cada variable sobre el y_target de la prectica train test split###\n",
    "    sns.set(rc={'figure.figsize':(35,4)})\n",
    "    sns.heatmap(pd.concat([X_df, pd.DataFrame(y_df)], axis=1).corr().iloc[[-1]], annot=True);\n",
    "    ### aca no se que significan los parametros iloc-1 y annot= True (anota los valores dentro de las celdas)\n",
    "\n",
    "    display(pd.DataFrame(data_eval))\n",
    "    display(pd.DataFrame(scores_eval))\n",
    "\n",
    "    retorno = dict()\n",
    "    retorno = { \"linear\": lm, \"ridge\": lm_ridge_cv, \"lasso\": lm_lasso_cv }\n",
    "\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gba = pd.read_csv('df_gba.csv', index_col=0)\n",
    "df_gba = df_gba[(df_gba.surface_total_in_m2.notnull())\n",
    "                  & (df_gba.price_usd_per_m2.notnull())\n",
    "                  & (df_gba.rooms.notnull())\n",
    "                  & (df_gba.provincia.notnull())]\n",
    "df_gba.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_gba = outliers( df = df_gba, criterio = 'provincia', p_z_score = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_gba_norte = df_gba[( df_gba.provincia == 'Bs.As. G.B.A. Zona Norte' )]\n",
    "db_gba_sur = df_gba[( df_gba.provincia == 'Bs.As. G.B.A. Zona Sur' )]\n",
    "db_gba_oeste = df_gba[( df_gba.provincia == 'Bs.As. G.B.A. Zona Oeste' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_gba_norte_dummies = preparar_df_gba( db_gba_norte )\n",
    "\n",
    "db_gba_sur_dummies = preparar_df_gba( db_gba_sur )\n",
    "\n",
    "db_gba_oeste_dummies = preparar_df_gba( db_gba_oeste )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza y separación, para el analisis de regresión vamos a tener:\n",
    "\n",
    "Zona Norte: 8139 filas y 29 columnas\n",
    "\n",
    "Zona Sur: 3153 filas 32 columnas\n",
    "\n",
    "Zona Oeste: 3485 filas y 28 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_norte = df_fit_transform( df = db_gba_norte_dummies, y_val = 'price_usd_per_m2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_sur = df_fit_transform( df = db_gba_sur_dummies, y_val = 'price_usd_per_m2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_oeste = df_fit_transform( df = db_gba_oeste_dummies, y_val = 'price_usd_per_m2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_gba_sur['linear'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Provincia de Buenos Aires](#Análisis-de-Propiedades-en-Provincia-de-Buenos-Aires)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de propiedades en Bs As provincia ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov = pd.read_csv('df_bs_as_prov.csv', index_col=0)\n",
    "display(df_bs_as_prov.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_bs_as_prov.sample(10))#elegimos un sample de 10 para que el muestreo sea aleatorio\n",
    "df_bs_as_prov.isnull().sum() # Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_bs_as_prov  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 2: \n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs_as_prov=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov['price_usd_per_m2'].describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2, rooms y localidad.\n",
    "df_bs_as_prov = df_bs_as_prov[(df_bs_as_prov.surface_total_in_m2.notnull())\\\n",
    "                  & (df_bs_as_prov.price_usd_per_m2.notnull())\\\n",
    "                  & (df_bs_as_prov.rooms.notnull())\n",
    "                  & (df_bs_as_prov.localidad.notnull())]\n",
    "df_bs_as_prov.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generamos las dummies para barrios (usando la columna de localidad que es la que contiene dicha información)\n",
    "bs_as_prov_dummies = pd.get_dummies(df_bs_as_prov.localidad, prefix='localidad')\n",
    "bs_as_prov_dummies.columns\n",
    "df_bs_as_prov = pd.concat([df_bs_as_prov, bs_as_prov_dummies], axis=1) #concatenamos las dummies generadas con el df de gba\n",
    "df_bs_as_prov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_bs_as_prov.shape)\n",
    "df_amen_bs_as_prov = df_bs_as_prov['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_bs_as_prov =  df_bs_as_prov['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_bs_as_prov, df_amen2_bs_as_prov], axis=1))\n",
    "plot = (100 * df_bs_as_prov['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el contador de las amenities en Bs As provincia. Decidimos incluirlas como feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresión. \n",
    "df_bs_as_prov.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_bs_as_prov.head())\n",
    "display(df_bs_as_prov.shape)\n",
    "display(df_bs_as_prov['price_usd_per_m2'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es1 = df_bs_as_prov[df_bs_as_prov['price_usd_per_m2']>=8000.00]\n",
    "quien_es1 #eliminamos la propiedad ya que es de 20m2 ytiene 7 habitaciones ya creemos que no es posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bs_as_prov.drop(46162, axis=0, inplace=True)\n",
    "display(df_bs_as_prov.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza, para el analisis de regresión vamos a tener 5942 filas y 89 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_bs_as_prov = df_bs_as_prov.drop('price_usd_per_m2', axis=1)\n",
    "y_bs_as_prov = df_bs_as_prov.price_usd_per_m2\n",
    "display(X_bs_as_prov.shape)#MODIFIQUE Q ESTABA MAL\n",
    "display(y_bs_as_prov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bs_as_prov, y_bs_as_prov, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\")\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Patagonia](#Análisis-de-propiedades-en-Patagonia)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de propiedades en Patagonia ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patagonia = pd.read_csv('df_patagonia.csv', index_col=0)\n",
    "display(df_patagonia.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_patagonia.sample(5))#elegimos un sample de 10 para que el muestreo sea aleatorio\n",
    "display(df_patagonia.isnull().sum())\n",
    "display(df_patagonia['price_usd_per_m2'].describe())# Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_patagonia \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard fueron considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patagonia=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_patagonia.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_patagonia['price_usd_per_m2'].describe()  #remoción correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quienes2 = df_patagonia[df_patagonia['price_usd_per_m2']==10500.00]\n",
    "quienes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Como Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformo dicha columna a variables dummies\n",
    "patagonia_dummies = pd.get_dummies(df_patagonia.provincia, prefix='Provincia_de')\n",
    "patagonia_dummies.columns\n",
    "df_pat = pd.concat([df_patagonia, patagonia_dummies], axis=1) #concatenamos las dummies generadas con el df de patagonia\n",
    "df_pat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amen_pat = df_pat['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_pat =  df_pat['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_pat, df_amen2_pat], axis=1))\n",
    "plot = (100 * df_pat['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresión. Saco del df el contador de amenities\n",
    "df_pat.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "df_pat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2,rooms.\n",
    "df_patagonia = df_pat[(df_pat.surface_total_in_m2.notnull())\\\n",
    "                  & (df_pat.price_usd_per_m2.notnull())\\\n",
    "                  & (df_pat.rooms.notnull())]\n",
    "display(df_patagonia.isnull().sum())\n",
    "display(df_patagonia.shape)\n",
    "display(df_patagonia['price_usd_per_m2'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza, para el analisis de regresión vamos a tener 158 filas y 23 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlación en Seaborn usando heatmap\n",
    "\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_patagonia.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_patagonia = df_patagonia.drop('price_usd_per_m2', axis=1)\n",
    "y_patagonia = df_patagonia.price_usd_per_m2\n",
    "display(X_patagonia.shape)\n",
    "display(y_patagonia.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_patagonia, y_patagonia, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando refacción\n",
    "df_patagonia.drop(['refaccion'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_patagonia.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Región Pampeana](#Análisis-de-propiedades-en-Región-Pampeana)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de propiedades en la región pampeana ###\n",
    "**Nota: No agrupamos a Bs As en este DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pampeana = pd.read_csv('df_pampeana.csv', index_col=0)\n",
    "display(df_pampeana.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_pampeana.sample(5))#elegimos un sample  para que el muestreo sea aleatorio\n",
    "display(df_pampeana.isnull().sum()) # Visualización de las columnas con valores null\n",
    "display(df_pampeana['price_usd_per_m2'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos un super outlier. Empezamos a pensar que hay valores que no estaban en usd sino en pesos y no supimos verlo en el primer desafio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quienes3 = df_pampeana[df_pampeana['price_usd_per_m2']==600000.00] #como tiene rooms en null cuando hagamos el filtro por nulls (que es antes de la regresion) va a desaparecer\n",
    "quienes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_pampeana  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 2: \n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pampeana=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pampeana.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2,rooms y provincia.\n",
    "df_pampeana = df_pampeana[(df_pampeana.surface_total_in_m2.notnull())\\\n",
    "                  & (df_pampeana.price_usd_per_m2.notnull())\\\n",
    "                  & (df_pampeana.rooms.notnull())\\\n",
    "                  & (df_pampeana.provincia.notnull())]\n",
    "df_pampeana.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pampeana['price_usd_per_m2'].describe()  #remoción correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quien_es4 = df_pampeana[df_pampeana['price_usd_per_m2']==6000.00] #\n",
    "quien_es4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 rooms nunca pueden ocupar 20m2. Procedemos a eliminar esta fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pampeana.drop(40075, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformo dicha columna a variables dummies\n",
    "pampeana_dummies = pd.get_dummies(df_pampeana.provincia, prefix='Provincia_de')\n",
    "pampeana_dummies.columns\n",
    "df_pam = pd.concat([df_pampeana, pampeana_dummies], axis=1) #concatenamos las dummies generadas con el df de patagonia\n",
    "df_pam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_amen_pam = df_pam['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_pam =  df_pam['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_pam, df_amen2_pam], axis=1))\n",
    "plot = (100 * df_pam['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresión\n",
    "df_pam.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "df_pam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pam['price_usd_per_m2'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlación en Seaborn usando heatmap\n",
    "\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_pam.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza, para el analisis de regresión vamos a tener 2697 filas y 22 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_pampeana = df_pam.drop('price_usd_per_m2', axis=1)\n",
    "y_pampeana = df_pam.price_usd_per_m2\n",
    "display(X_pampeana.shape)\n",
    "display(y_pampeana.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pampeana, y_pampeana, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asignamos los alphas y definimos kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 100, 300)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Noroeste](#Análisis-de-propiedades-en-Noroeste)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de propiedades en la región noroeste ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_noroeste = pd.read_csv('df_noroeste.csv', index_col=0)\n",
    "display(df_noroeste.shape)#Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_noroeste.sample(10))#elegimos un sample  para que el muestreo sea aleatorio\n",
    "display(df_noroeste.isnull().sum())\n",
    "display(df_noroeste['price_usd_per_m2'].describe())# Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quien_es5 = df_noroeste[df_noroeste['price_usd_per_m2']>=5400] #Esta propiedad tiene rooms en nan (y ya hicimos el regex en titulo y descripcion y sabemos que no hay info). Va a ser eliminada mas abajo con los nulls\n",
    "quien_es5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_noroeste  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noroeste=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_noroeste.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformo dicha columna a variables dummies\n",
    "noroeste_dummies = pd.get_dummies(df_noroeste.provincia, prefix='Provincia_de')\n",
    "noroeste_dummies.columns\n",
    "df_noroeste = pd.concat([df_noroeste, noroeste_dummies], axis=1) #concatenamos las dummies generadas con el df de patagonia\n",
    "df_noroeste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2 y rooms \n",
    "df_noroeste = df_noroeste[(df_noroeste.surface_total_in_m2.notnull())\\\n",
    "                  & (df_noroeste.price_usd_per_m2.notnull())\\\n",
    "                  & (df_noroeste.rooms.notnull())]\n",
    "df_noroeste.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresión\n",
    "df_noroeste.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "display(df_noroeste.head())\n",
    "display(df_noroeste['price_usd_per_m2'].describe())\n",
    "display(df_noroeste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza, quedan muy pocos datos y para el analisis de regresión vamos a tener 30 filas y 24 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlación en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_noroeste.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos refacción, PH, store, barrio cerrado, vigilancia y las provincias de Jujuy y La Rioja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando las variables irrelevantes\n",
    "df_noroeste.drop(['refaccion', 'store', 'PH', 'vigilancia', 'barrio_cerrado', 'Provincia_de_Jujuy',\n",
    "                  'Provincia_de_La Rioja'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos la matriz de correlación en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_noroeste.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_noroeste = df_noroeste.drop('price_usd_per_m2', axis=1)\n",
    "y_noroeste = df_noroeste.price_usd_per_m2\n",
    "display(X_noroeste.shape)\n",
    "display(y_noroeste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_noroeste, y_noroeste, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asignamos los alphas\n",
    "alphas = np.linspace(0.1, 100, 300)\n",
    "\n",
    "# Definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\",size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Nordeste](#Análisis-de-propiedades-en-Nordeste)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de propiedades en la región nordeste ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nordeste = pd.read_csv('df_nordeste.csv', index_col=0)\n",
    "display(df_nordeste.shape) #Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_nordeste.sample(10))#elegimos un sample  para que el muestreo sea aleatorio\n",
    "display(df_nordeste.isnull().sum())\n",
    "display(df_nordeste['price_usd_per_m2'].describe())# Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_nordeste  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nordeste=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nordeste.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nordeste['price_usd_per_m2'].describe()  #remoción correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quien_es5 = df_nordeste[df_nordeste['price_usd_per_m2']>=7000] #Es posible que esta propiedad este bien cotizada en Puerto Iguazu que es una zona turistica\n",
    "quien_es5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#como Provincia es la columna que vamos a utilizar para las dummies tiene 0 nulls, transformamos dicha columna a variables dummies\n",
    "nordeste_dummies = pd.get_dummies(df_nordeste.provincia, prefix='Provincia')\n",
    "nordeste_dummies.columns\n",
    "df_nord = pd.concat([df_nordeste, nordeste_dummies], axis=1) #concatenamos las dummies generadas con el df de la region Nordeste\n",
    "df_nord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no van a ser utilizadas para la regresión\n",
    "df_nord.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', \n",
    "             'price_aprox_usd', 'pileta','parrilla', 'gimnasio', 'sauna', 'laundry', \n",
    "             'playroom', 'sum', 'sala_reuniones','restaurant', 'quincho'],\n",
    "              inplace=True, axis=1)\n",
    "df_nord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amen_nord = df_nordeste['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_nord =  df_nordeste['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_nord, df_amen2_nord ], axis=1))\n",
    "plot = (100 * df_nord['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las filas con valores nan para surface_total_in_m2,price_usd_per_m2,rooms.\n",
    "df_nordeste = df_nord[(df_nord.surface_total_in_m2.notnull())\\\n",
    "                  & (df_nord.price_usd_per_m2.notnull())\\\n",
    "                  & (df_nord.rooms.notnull())]\n",
    "display(df_nordeste.isnull().sum())\n",
    "display(df_nordeste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Después de esta limpieza, para el analisis de regresión vamos a tener 268 filas y 23 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de correlación en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (25, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_nordeste.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_nordeste = df_nordeste.drop('price_usd_per_m2', axis=1)\n",
    "y_nordeste = df_nordeste.price_usd_per_m2\n",
    "display(X_nordeste.shape)\n",
    "display(y_nordeste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nordeste, y_nordeste, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y definimos kf para utilizar kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando las variables irrelevantes\n",
    "df_nordeste.drop(['refaccion', 'store', 'Provincia_Formosa'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Propiedades en Cuyo](#Análisis-de-propiedades-en-Cuyo)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Análisis de propiedades en la región de Cuyo ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cuyo = pd.read_csv('df_cuyo.csv', index_col=0)\n",
    "display(df_cuyo.shape) #Nos fijamos con cuantas filas y columnas arrancamos\n",
    "display(df_cuyo.sample(10))#selección de 10 ejemplares al azar\n",
    "display(df_cuyo.isnull().sum())\n",
    "display(df_cuyo['price_usd_per_m2'].describe())# Visualización de las columnas con valores null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_cuyo  \n",
    "localidades=df.localidad.unique()\n",
    "for x in localidades:\n",
    "       mean_1 = np.mean(df.price_usd_per_m2[df.localidad==x])\n",
    "       std_1 =np.std(df.price_usd_per_m2[df.localidad==x])\n",
    "       mean_2 = np.mean(df.surface_total_in_m2[df.localidad==x])\n",
    "       std_2 =np.std(df.surface_total_in_m2[df.localidad==x])\n",
    "\n",
    "       for index2, y in df[df.localidad==x].iterrows():\n",
    "               if(std_1!=0):\n",
    "                   z_score= (y.price_usd_per_m2 - mean_1)/std_1\n",
    "                   if np.abs(z_score) > 3: # cualquier punto fuera de 3 desviaciones estandard son considerados outlier.\n",
    "                       df.loc[index2,'outlier']=\"YES\"\n",
    "               if(std_2!=0):\n",
    "                   z_score2= (y.surface_total_in_m2 - mean_2)/std_2\n",
    "                   if np.abs(z_score2) > 3:\n",
    "                       df.loc[index2,'outlier']=\"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuyo=df[(df.outlier!='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cuyo.drop(['outlier'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuyo['price_usd_per_m2'].describe()  #remoción correcta de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuyo_dummies = pd.get_dummies(df_cuyo.provincia, prefix='Provincia')\n",
    "df_cuyo = pd.concat([df_cuyo, cuyo_dummies], axis=1) \n",
    "display(df_cuyo.shape)\n",
    "display(df_cuyo.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuyo = df_cuyo[(df_cuyo.surface_total_in_m2.notnull())\\\n",
    "                  & (df_cuyo.price_usd_per_m2.notnull())\\\n",
    "                  & (df_cuyo.rooms.notnull())]\n",
    "display(df_cuyo.shape)\n",
    "display(df_cuyo.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay pocas propiedades en la región de Cuyo después de la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amen_cuyo = df_cuyo['amenities'].value_counts(normalize=True, dropna=False)\n",
    "df_amen2_cuyo =  df_cuyo['amenities'].value_counts()\n",
    "display(pd.concat([df_amen_cuyo, df_amen2_cuyo], axis=1))\n",
    "plot = (100 * df_cuyo['amenities'].value_counts(normalize = True)).plot(kind='bar', title='amenities %', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos las colamumnas que no van a ser utilizadas para la regresión\n",
    "df_cuyo.drop(['lat-lon', 'lat', 'lon', 'localidad', 'barrio', 'provincia', 'geonames_id', 'price_aprox_usd',\n",
    "            'pileta', 'parrilla', 'gimnasio', 'sauna', 'laundry', 'playroom', 'sum', 'sala_reuniones', \n",
    "            'restaurant', 'quincho',], inplace=True, axis=1)\n",
    "display(df_cuyo.shape)\n",
    "display(df_cuyo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esta limpieza, para el analisis de regresión vamos a tener 44 filas y 22 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de correlación en Seaborn usando heatmap\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "sns.set(font_scale=1.3)\n",
    "sns.heatmap(df_cuyo.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estrenar, en refacción o normal no parecen estar aportando datos a la correlación. Tampoco vigilancia, PH y la provincia de San Juan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeando las variables irrelevantes\n",
    "df_cuyo.drop(['vigilancia', 'estrenar','refaccion', 'Provincia_San Juan', 'normal', 'PH'], axis=1, inplace=True)\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (25, 15)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.heatmap(df_cuyo.corr(), annot=True, fmt='.2f', cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y\n",
    "X_df = df_cuyo.drop('price_usd_per_m2', axis=1)\n",
    "y_df = df_cuyo.price_usd_per_m2\n",
    "display(X_df.shape)\n",
    "display(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos para train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los alphas y kFold como estrategia de cross validation.\n",
    "alphas = np.linspace(0.1, 1000, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos los modelos \n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=alphas, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos\n",
    "modelo_lr = lm.fit(X_train, y_train)\n",
    "modelo_ridge = lm_ridge_cv.fit(X_train, y_train)\n",
    "modelo_lasso = lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el alpha que eligio para cada modelo\n",
    "print('El 𝛼 estimado en Ridge: %.4f'% lm_ridge_cv.alpha_,'\\n'\n",
    "      'El 𝛼 estimado en LASSO: %.4f'% lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el Score de entrenamiento de cada modelo, si dan muy altos es porque estan overfiteados\n",
    "\n",
    "print(\" Score Train Lineal: %.4f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.4f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.4f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test R2 lineal= %.4f\\n\" % r2_score(y_test, y_pred_lm),\n",
    "      \"Test R2 Ridge = %.4f\\n\" %  r2_score(y_test, y_pred_ridge),\n",
    "      \"Test R2 Lasso = %.4f\" %  r2_score(y_test, y_pred_lasso))\n",
    "print()\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo Regresion Lineal\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_lm, y_test, s=30, c='r', marker='.', zorder=10)\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.xlabel(\"Predicciones usando Regresion Lineal\", size = 12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo RIDGE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=10)\n",
    "plt.scatter(y_pred_ridge, y_test, s=30, c='g', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RIDGE\", size = 12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist(bins=100, figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados para el modelo LASSO\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test,y_test, s=5)\n",
    "plt.scatter(y_pred_lasso, y_test, s=30, c='purple', marker='.', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando LASSO\", size=12)\n",
    "plt.ylabel(\"Valores reales precio en USD por m2\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Análisis de Sample en CABA](#Análisis-de-Sample-en-CABA)\n",
    "[Volver](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el Dataframe de los 100 Samples de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caba_sample = pd.read_csv('caba_sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos un Dataframe por cada tipo de Propiedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph_sample = df_caba_sample[(df_caba_sample.PH== 1)]\n",
    "df_apartment_sample = df_caba_sample[(df_caba_sample.apartment== 1)]\n",
    "df_store_sample = df_caba_sample[(df_caba_sample.store== 1)]\n",
    "df_house_sample = df_caba_sample[(df_caba_sample.house== 1)]\n",
    "\n",
    "df_ph_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "df_apartment_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "df_store_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)\n",
    "df_house_sample.drop(['apartment', 'store', 'PH', 'house'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion a utilizar para predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_sample_caba( df, scaler, linear_model, ridge_model, lasso_model ):\n",
    "    # definimos X e y\n",
    "    X_df = df.drop('price_usd_per_m2', axis=1)\n",
    "    y_df = df.price_usd_per_m2\n",
    "\n",
    "    # Escalamos los valores con el escalador fiteado al momento de armar el Modelo, para cada tipo de propiedad,\n",
    "    # ya que los modelos fueron entrenados con los valores escalados.\n",
    "    X_df = scaler.transform(X_df)\n",
    "\n",
    "    # Predecimos con modelo lineal\n",
    "    y_pred_lm = linear_model.predict(X_df)\n",
    "    \n",
    "    # Predecimos con Ridge\n",
    "    y_pred_ridge = ridge_model.predict(X_df)\n",
    "    \n",
    "    # Predecimos con Lasso\n",
    "    y_pred_lasso = lasso_model.predict(X_df)\n",
    "\n",
    "    ### Visualizamos y comparamos los valores de cada predictor con el real del dataframe original ###\n",
    "    lista = list()\n",
    "    for idx, val in enumerate( X_df ):\n",
    "      lista.append( { \"real\": y_df.iloc[ idx ], \"linear\": y_pred_lm[ idx ], \"ridge\":y_pred_ridge[ idx ], \"lasso\":y_pred_lasso[ idx ] } )\n",
    "\n",
    "    df_retorno = pd.DataFrame(lista)\n",
    "    display(df_retorno)\n",
    "    return df_retorno\n",
    "    #############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ph = prediccion_sample_caba( df = df_ph_sample, scaler = scaler_ph, linear_model = modelo_lr_ph, ridge_model = modelo_ridge_ph, lasso_model = modelo_lasso_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(pred_ph.real,pred_ph.real, label='Real')\n",
    "plt.scatter(pred_ph.linear, pred_ph.real, s=100, c='r', marker='o', zorder=10, label='Lineal')\n",
    "plt.scatter(pred_ph.ridge, pred_ph.real, s=100, c='g', marker='+', zorder=10, label='Ridge')\n",
    "plt.scatter(pred_ph.lasso, pred_ph.real, s=100, c='purple', marker='v', zorder=10, label='Lasso')\n",
    "plt.xlabel(\"Predicciones \", size=12)\n",
    "plt.ylabel(\"Valores reales PH precio en USD por m2\", size=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de Apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_ap = prediccion_sample_caba( df = df_apartment_sample, scaler = scaler_ap, linear_model = modelo_lr_ap, ridge_model = modelo_ridge_ap, lasso_model = modelo_lasso_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ap = pred_ap[ (pred_ap.real < 21085) ]\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(pred_ap.real,pred_ap.real, label='Real')\n",
    "plt.scatter(pred_ap.linear, pred_ap.real, s=100, c='r', marker='o', zorder=10, alpha=0.3, label='Lineal')\n",
    "plt.scatter(pred_ap.ridge, pred_ap.real, s=200, c='g', marker='+', zorder=10, label='Ridge')\n",
    "plt.scatter(pred_ap.lasso, pred_ap.real, s=100, c='purple', marker='v', zorder=10, alpha=0.3, label='Lasso')\n",
    "plt.xlabel(\"Predicciones \", size=12)\n",
    "plt.ylabel(\"Valores reales Apartment precio en USD por m2\", size=12)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ho = prediccion_sample_caba( df = df_house_sample, scaler = scaler_ho, linear_model = modelo_lr_ho, ridge_model = modelo_ridge_ho, lasso_model = modelo_lasso_ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos el Sample de House\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(pred_ho.real,pred_ho.real, label='Real')\n",
    "plt.scatter(pred_ho.linear, pred_ho.real, s=100, c='r', marker='o', zorder=10, label='Lineal')\n",
    "plt.scatter(pred_ho.ridge, pred_ho.real, s=100, c='g', marker='+', zorder=10, label='Ridge')\n",
    "plt.scatter(pred_ho.lasso, pred_ho.real, s=100, c='purple', marker='v', zorder=10, label='Lasso')\n",
    "plt.xlabel(\"Predicciones \", size=12)\n",
    "plt.ylabel(\"Valores reales House precio en USD por m2\", size=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para store solo tiene una propiedad y no hicimos el grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediccion_sample_caba( df = df_store_sample, scaler = scaler_st, linear_model = modelo_lr_st, ridge_model = modelo_ridge_st, lasso_model = modelo_lasso_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
